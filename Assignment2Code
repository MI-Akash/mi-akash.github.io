import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import PoseWithCovarianceStamped
from geometry_msgs.msg import Twist, PoseStamped
from rclpy.qos import QoSProfile, QoSReliabilityPolicy, QoSDurabilityPolicy, QoSHistoryPolicy
from cv_bridge import CvBridge
import cv2
import torch
import time
import torchvision
from torchvision.transforms import ToTensor
from ultralytics import YOLO
from qdrant_client import QdrantClient
from qdrant_client.http.models import PointStruct
import math 
from rclpy.executors import MultiThreadedExecutor


class VisionBotNode(Node):
    def __init__(self):
        super().__init__('vision_bot_core')

        qos_cfg = QoSProfile(
            reliability=QoSReliabilityPolicy.RELIABLE,
            durability=QoSDurabilityPolicy.TRANSIENT_LOCAL,
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=10
        )

        self.pose_listener = self.create_subscription(
            PoseWithCovarianceStamped, 
            '/amcl_pose', 
            self.pose_update_handler, 
            qos_cfg
        )

        self.image_sub = self.create_subscription(Image, '/camera/image_raw', self.image_input_cb, 10)
        self.image_pub = self.create_publisher(Image, '/vision_output', 10)

        self.img_bridge = CvBridge()
        self.detector = YOLO('yolov8s.pt').to('cuda' if torch.cuda.is_available() else 'cpu')
        self.vector_store = QdrantClient(url="http://localhost:6333")
        self.bot_pose = (0.0, 0.0, 0.0)

        self.get_logger().info("Visual detection system activated.")

    def pose_update_handler(self, msg):
        px = msg.pose.pose.position.x
        py = msg.pose.pose.position.y
        orient = msg.pose.pose.orientation

        siny = 2.0 * (orient.w * orient.z + orient.x * orient.y)
        cosy = 1.0 - 2.0 * (orient.y**2 + orient.z**2)
        yaw = math.atan2(siny, cosy)

        self.bot_pose = (px, py, yaw)
        self.get_logger().info(f"Updated robot pose: x={px:.2f}, y={py:.2f}, yaw={yaw:.2f}")

    def image_input_cb(self, msg):
        try:
            frame = self.img_bridge.imgmsg_to_cv2(msg, 'bgr8')
        except Exception as error:
            self.get_logger().error(f"Image decode failed: {str(error)}")
            return

        predictions = self.detector(frame, verbose=False)[0]
        frame = self.annotate_detections(frame, predictions)
        self.archive_detections(predictions, frame)

        try:
            result_msg = self.img_bridge.cv2_to_imgmsg(frame, 'bgr8')
            self.image_pub.publish(result_msg)
        except Exception as error:
            self.get_logger().error(f"Publish error: {str(error)}")

    def annotate_detections(self, img, dets, thresh=0.3):
        for obj in dets.boxes:
            prob = obj.conf[0].item()
            class_id = int(obj.cls[0].item())

            if prob >= thresh:
                x_min, y_min, x_max, y_max = map(int, obj.xyxy[0])
                label = self.detector.names[class_id]
                self.get_logger().info(f"Detected: {label} ({prob:.2f})")

                cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
                cv2.putText(img, f"{label} {prob:.2f}", (x_min, y_min - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
        return img

    def archive_detections(self, dets, img):
        archive_name = "embedded_vision_vault"

        try:
            _ = self.vector_store.get_collection(collection_name=archive_name)
        except Exception:
            try:
                net = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)
                net.fc = torch.nn.Identity()
                with torch.no_grad():
                    dummy = torch.rand(1, 3, 224, 224)
                    vec_dim = net(dummy).squeeze().numpy().shape[0]
                self.vector_store.create_collection(
                    collection_name=archive_name,
                    vectors_config={"size": vec_dim, "distance": "Cosine"}
                )
                self.get_logger().info(f"Collection '{archive_name}' initiated.")
            except Exception as fail:
                self.get_logger().error(f"Failed to create archive: {str(fail)}")
                return

        now_stamp = time.time()
        embedder = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)
        embedder.fc = torch.nn.Identity()
        embedder.eval()

        with torch.no_grad():
            tensor_img = ToTensor()(img).unsqueeze(0)
            features = embedder(tensor_img).squeeze().numpy()

        entries = []
        for obj in dets.boxes:
            prob = obj.conf[0].item()
            class_id = int(obj.cls[0].item())

            if prob >= 0.3:
                x1, y1, x2, y2 = map(int, obj.xyxy[0])
                label = self.detector.names[class_id]

                entry = PointStruct(
                    id=int(now_stamp * 1000) + len(entries),
                    vector=features.tolist(),
                    payload={
                        "timestamp": now_stamp,
                        "detection": {
                            "label": label,
                            "confidence": prob,
                            "bounding_box": {"x1": x1, "y1": y1, "x2": x2, "y2": y2}
                        },
                        "robot_position": {
                            "x": self.bot_pose[0], 
                            "y": self.bot_pose[1],
                            "yaw": self.bot_pose[2]
                        },
                        "frame_metadata": {
                            "total_detections": len(dets.boxes),
                            "detection_threshold": 0.3
                        }
                    }
                )
                entries.append(entry)

        if entries:
            try:
                self.vector_store.upsert(collection_name=archive_name, points=entries)
                self.get_logger().info(f"Stored {len(entries)} detections in Qdrant.")
            except Exception as fail:
                self.get_logger().error(f"Log failure: {str(fail)}")
        else:
            self.get_logger().info("No detections above threshold to store.")

def launch(args=None):
    rclpy.init(args=args)
    vision_node = VisionBotNode()
    worker = MultiThreadedExecutor(num_threads=4)
    worker.add_node(vision_node)

    try:
        worker.spin()
    finally:
        worker.shutdown()
        vision_node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    launch()
